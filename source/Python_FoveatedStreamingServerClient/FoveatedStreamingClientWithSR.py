import time
import cv2
import numpy as np
import subprocess as sp
import sys
import queue
from bcolors import bcolors
import csv
import tensorflow as tf


class FoveatedStreamingClient:
    """
    Similiar to the  streaming client but with superresolution instead of bicubic resizing
    """

    def __init__(self, radius: int, size_total: tuple, size_stream_foveated: tuple,
                 size_stream_peripheral: tuple) -> None:
        self.radius = radius
        self.size_total = size_total
        self.size_stream_foveated = size_stream_foveated
        self.size_stream_peripheral = size_stream_peripheral
        self.bounds_detect_circle = radius // 2 - 20 // 2, radius // 2 + 20
        self.threads = []
        self.ImageQueue = queue.Queue()
        self.end_of_stream = False
        self.last_frame_received = time.process_time()
        self.Generator = tf.keras.models.load_model('GanModel/12_Generator',
                                                    custom_objects={'tf': tf, 'pixel_shuffle': self.pixel_shuffle})
        self.Generator.summary()
        self.csv_lines = "12_ResNet"
        self.video_writer = None

    def initialize_cv2(self) -> None:
        """
        Initialize OpenCV and a video writer for saving the received video
        :return: None
        """
        cv2.namedWindow('image')
        cv2.resizeWindow('image', self.size_total[0], self.size_total[1])
        fourcc = cv2.VideoWriter_fourcc('M', 'J', 'P', 'G')
        self.video_writer = cv2.VideoWriter("Examples/output_low_res_peripheral.avi", fourcc, 10,
                                            self.size_stream_peripheral)

    def initialize_ffmpeg(self, sdp_file: str) -> sp.Popen:
        """
        Initialize FFmpeg as client, commands used as described in the MA
        :param sdp_file: path to the sdp_file generated by the server
        :return: A opend subprocess with one stream
        """
        command = ['FFMPEG',
                   '-protocol_whitelist', 'udp,rtp,file,pipe,crypto,data',
                   '-hwaccel_output_format', 'cuda',
                   '-probesize', '32',
                   '-analyzeduration', '0',
                   '-fflags', 'nobuffer',
                   '-flags', 'low_delay',
                   '-i', sdp_file,
                   '-vcodec', 'rawvideo',
                   '-pix_fmt', 'bgr24',
                   '-f', 'image2pipe', '-']
        return sp.Popen(command, stdout=sp.PIPE)

    def calculate_masked_circle(self, img: cv2.UMat, coordinates: tuple) -> cv2.UMat:
        """
        Calculate the final image of the received streams by cropping a circle with the given radius in the foveated
        stream and extending it with black borders to the final size. Additionally, create a mask for the peripheral
        image for merging them accordingly.
        :param img: the foveated image
        :param coordinates: at which position the foveated image is placed on the
        :return: the extended foveated image and the mask for the peripheral area
        """
        mask_foveated = cv2.UMat(np.zeros(self.size_stream_foveated[::-1], dtype=np.uint8))
        cv2.circle(mask_foveated, (128, 128), 125, (255, 255, 255), -1, 0, 0)
        mask_peripheral = cv2.UMat(np.zeros(self.size_total[::-1], dtype=np.uint8))
        cv2.circle(mask_peripheral, coordinates, 125, (255, 255, 255), -1, 0, 0)

        width, height = self.size_total
        width = width - 2 * self.radius
        height = height - 2 * self.radius
        left = coordinates[0] - self.radius
        right = width - left
        top = coordinates[1] - self.radius
        bottom = height - top

        img = cv2.bitwise_or(img, img, mask=mask_foveated)
        img = cv2.copyMakeBorder(img, top, bottom, left, right, cv2.BORDER_CONSTANT, value=[0, 0, 0])
        result = cv2.bitwise_or(img, img)
        return result, mask_peripheral

    def stack_images(self, image_1: cv2.UMat, image_2: cv2.UMat, mask) -> cv2.UMat:
        """
        Stack the foveated and the peripheral image together
        :param image_1: peripheral area
        :param image_2: extended foveated area
        :param mask: mask for peripheral area
        :return: merged image
        """
        new_img = cv2.bitwise_and(image_1, image_1, mask=mask)
        return cv2.add(new_img, image_2)

    def get_coords_out_of_border(self, coords: tuple) -> tuple:
        """
        Get coords out of boder when too close to the edge
        :param coords: coords of gaze
        :return: corrected coords if necesessary
        """
        x_coord, y_coord = coords

        if x_coord < self.radius:
            x_coord = self.radius + 1
        elif x_coord > self.size_total[0] - self.radius:
            x_coord = self.size_total[0] - 2 * self.radius - 1

        if y_coord < self.radius:
            y_coord = self.radius + 1
        elif y_coord > self.size_total[1] - self.radius:
            y_coord = self.size_total[1] - 2 * self.radius - 1

        return x_coord, y_coord

    def extract_area(self, area: str, size: tuple) -> cv2.UMat:
        """
        Extract image from hex to numpy array
        :param area: image in hex
        :param size: size of the image
        :return: image as numpy array
        """
        area = np.frombuffer(area, dtype='uint8').reshape(size[1], size[0], 3)
        return area

    def read_error(self, proc_peripheral: sp.Popen, proc_foveated: sp.Popen):
        """
        Read error stdout
        :param proc_peripheral: subprocess of error channel of peripheral stream
        :param proc_foveated:  subprocess of error channel of foveated stream
        :return: None
        """
        try:
            while proc_peripheral.stderr.readable() and proc_foveated.stderr.readable():
                print(f"{bcolors.WARNING}Peripheral: ", proc_peripheral.stderr.readline(), f"{bcolors.ENDC}")
                print(f"{bcolors.WARNING}Foveated: ", proc_foveated.stderr.readline(), f"{bcolors.ENDC}")
            print('finished errors')
        except SystemExit:
            pass

    def stream(self):
        """
        Initialize both subprocessses for both streams including error channels in threads.
        Streaming is performed synced, as performing ML in threads is hard
        :return: None
        """
        self.initialize_cv2()

        sdp_file_peripheral = "VideoSettings/video_00_00_00_peripheral.sdp"
        sdp_file_foveated = "VideoSettings/video_00_00_00_foveated.sdp"
        proc_peripheral = self.initialize_ffmpeg(sdp_file_peripheral)
        proc_foveated = self.initialize_ffmpeg(sdp_file_foveated)
        size_peripheral = self.size_stream_peripheral[0] * (self.size_stream_peripheral[1]) * 3
        size_foveated = self.size_stream_foveated[0] * self.size_stream_foveated[1] * 3

        while not self.end_of_stream:

            frame_peripheral = proc_peripheral.stdout.read(size_peripheral)
            frame_foveated = proc_foveated.stdout.read(size_foveated)

            if frame_foveated == 0 or frame_peripheral == 0 or len(frame_foveated) == 0 or len(
                    frame_peripheral) == 0:
                print('end of stream')
                print('frame_foveated: ', frame_foveated)
                print('frame_peripheral: ', frame_peripheral)
                self.end_of_stream = True
                break

            peripheral_area_raw = self.extract_area(frame_peripheral, self.size_stream_peripheral)

            peripheral_area_raw = tf.expand_dims(peripheral_area_raw, axis=0)
            tic = time.perf_counter()
            peripheral_area = self.Generator(peripheral_area_raw)[0] # Perfom superresolution
            toc = time.perf_counter()
            peripheral_area = np.array(peripheral_area, dtype='uint8')

            time_elapsed = round(((toc - tic) * 1000), 4)
            print(f"performed calc in {time_elapsed:0.4f} miliseconds")
            self.csv_lines += f"\n{time_elapsed}"

            peripheral_area = cv2.UMat(peripheral_area)
            peripheral_area = cv2.resize(peripheral_area, self.size_total, cv2.INTER_CUBIC)
            foveated_area: cv2.UMat = self.extract_area(frame_foveated, self.size_stream_foveated)
            foveated_area = cv2.UMat(foveated_area)

            a, b = 960, 512
            img, mask = self.calculate_masked_circle(foveated_area, (a, b))
            result = self.stack_images(peripheral_area, img, cv2.bitwise_not(mask))

            cv2.imshow('image', result)
            print(f"performed calc in {time_elapsed:0.4f} miliseconds")
            self.csv_lines += f"\n{time_elapsed}"
            # self.video_writer.write(peripheral_area)
            self.last_frame_received = time.process_time()

            k = cv2.waitKey(20) & 0xFF
            if k == ord('q'):
                self.end_of_stream = True
                break

        for thread in self.threads:
            thread.join()

        cv2.destroyAllWindows()
        # self.video_writer.release()
        proc_peripheral.stdout.close()
        proc_peripheral.wait()
        proc_foveated.stdout.close()
        proc_foveated.wait()
        with open('Latency_4.csv', 'w', newline='') as file:
            writer = csv.writer(file)
            for line in self.csv_lines.splitlines():
                writer.writerow([line])
        sys.exit()

    def pixel_shuffle(self, scale):
        """
        Method for the RoboyGAN
        :param scale: scale on how the image will be rescaled
        :return: scaled image
        """
        return lambda x: tf.nn.depth_to_space(x, scale)


if __name__ == '__main__':
    gpus = tf.config.experimental.list_physical_devices('GPU')
    tf.config.threading.set_inter_op_parallelism_threads(6)
    if gpus:
        # Restrict TensorFlow to only allocate 1*X GB of memory on the first GPU
        try:
            tf.config.experimental.set_virtual_device_configuration(gpus[0],
                                                                    [tf.config.experimental.VirtualDeviceConfiguration(
                                                                        memory_limit=(1024 * 4))])
            logical_gpus = tf.config.experimental.list_logical_devices('GPU')
            print(len(gpus), "Physical GPUs,", len(logical_gpus), "Logical GPUs")
        except RuntimeError as e:
            # Virtual devices must be set before GPUs have been initialized
            print(e)

    client = FoveatedStreamingClient(128, (2048, 1024), (256, 256), (512, 256))
    client.stream()
