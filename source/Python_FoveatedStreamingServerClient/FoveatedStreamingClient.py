#!/usr/local/bin/python3
import time
import threading
import cv2
import numpy as np
import subprocess as sp
import sys
import concurrent.futures
import queue
from bcolors import bcolors


class FoveatedStreamingClient:
    def __init__(self, radius: int, size_total: tuple, size_stream_foveated: tuple,
                 size_stream_peripheral: tuple) -> None:
        """
        :param radius: of the foveated area
        :param size_total: how large the untouched before and after the streaming is e.g. 2048x1024
        :param size_stream_foveated: size in which the foveated area is transimited, based on the radius e.g. 256x256
        :param size_stream_peripheral: size in which the peripheral area is transmitted, e.g. 512x256
        """
        self.radius = radius
        self.size_total = size_total
        self.size_stream_foveated = size_stream_foveated
        self.size_stream_peripheral = size_stream_peripheral
        self.bounds_detect_circle = radius // 2 - 20 // 2, radius // 2 + 20
        self.threads = []
        self.ImageQueue = queue.Queue()
        self.end_of_stream = False
        self.last_frame_received = time.process_time()
        self.video_writer = None

    def initialize_cv2(self) -> None:
        """
        Initialize the OpenCV stuff including a video writer for saving a streamed video
        :return: None
        """
        cv2.namedWindow('image')
        cv2.resizeWindow('image', self.size_total[0], self.size_total[1])
        fourcc = cv2.VideoWriter_fourcc('M', 'J', 'P', 'G')
        self.video_writer = cv2.VideoWriter("Examples/output_low_res_peripheral.avi", fourcc, 10,
                                            self.size_stream_peripheral)

    def initialize_ffmpeg(self, sdp_file: str) -> sp.Popen:
        """
        Initialize FFmpeg as client, commands used as described in the MA
        :param sdp_file: path to the sdp_file generated by the server
        :return: A opend subprocess with one stream
        """
        command = ['FFMPEG',
                   '-protocol_whitelist', 'udp,rtp,file,pipe,crypto,data',
                   '-hwaccel_output_format', 'cuda',
                   '-probesize', '32',
                   '-analyzeduration', '0',
                   '-fflags', 'nobuffer',
                   '-flags', 'low_delay',
                   '-i', sdp_file,
                   '-vcodec', 'rawvideo',
                   '-pix_fmt', 'bgr24',
                   '-f', 'image2pipe', '-']
        return sp.Popen(command, stdout=sp.PIPE)

    def calculate_masked_circle(self, img: cv2.UMat, coordinates: tuple) -> cv2.UMat:
        """
        Calculate the final image of the received streams by cropping a circle with the given radius in the foveated
        stream and extending it with black borders to the final size. Additionally, create a mask for the peripheral
        image for merging them accordingly.
        :param img: the foveated image
        :param coordinates: at which position the foveated image is placed on the
        :return: the extended foveated image and the mask for the peripheral area
        """
        mask_foveated = cv2.UMat(np.zeros(self.size_stream_foveated[::-1], dtype=np.uint8))
        cv2.circle(mask_foveated, (128, 128), 125, (255, 255, 255), -1, 0, 0)
        mask_peripheral = cv2.UMat(np.zeros(self.size_total[::-1], dtype=np.uint8))
        cv2.circle(mask_peripheral, coordinates, 125, (255, 255, 255), -1, 0, 0)

        width, height = self.size_total
        width = width - 2 * self.radius
        height = height - 2 * self.radius
        left = coordinates[0] - self.radius
        right = width - left
        top = coordinates[1] - self.radius
        bottom = height - top

        img = cv2.bitwise_or(img, img, mask=mask_foveated)
        img = cv2.copyMakeBorder(img, top, bottom, left, right, cv2.BORDER_CONSTANT, value=[0, 0, 0])
        result = cv2.bitwise_or(img, img)
        return result, mask_peripheral

    def stack_images(self, image_1: cv2.UMat, image_2: cv2.UMat, mask) -> cv2.UMat:
        """
        Stack the foveated and the peripheral image together
        :param image_1: peripheral area
        :param image_2: extended foveated area
        :param mask: mask for peripheral area
        :return: merged image
        """
        new_img = cv2.bitwise_and(image_1, image_1, mask=mask)
        return cv2.add(new_img, image_2)

    def get_coords_out_of_border(self, coords: tuple) -> tuple:
        """
        Get coords out of boder when too close to the edge
        :param coords: coords of gaze
        :return: corrected coords if necesessary
        """
        x_coord, y_coord = coords

        if x_coord < self.radius:
            x_coord = self.radius + 1
        elif x_coord > self.size_total[0] - self.radius:
            x_coord = self.size_total[0] - 2 * self.radius - 1

        if y_coord < self.radius:
            y_coord = self.radius + 1
        elif y_coord > self.size_total[1] - self.radius:
            y_coord = self.size_total[1] - 2 * self.radius - 1

        return x_coord, y_coord

    def calc_frame(self, peripheral: str, foveated: str):
        """
        Combine the steps of merging the the foveated and the peripheral area by
        1) Extracting the image from hex
        2) Moving the images to GPU via OpenCV
        3) Resizing the peripheral area to its original size
        4) Calculate the masks
        5) Stacking the images
        :param peripheral: peripheral image as hex
        :param foveated: foveated image as hex
        :return: final image
        """
        peripheral_area: cv2.UMat = self.extract_area(peripheral, self.size_stream_peripheral)
        peripheral_area = cv2.UMat(peripheral_area)
        peripheral_area = cv2.resize(peripheral_area, self.size_total, cv2.INTER_CUBIC)
        foveated_area: cv2.UMat = self.extract_area(foveated, self.size_stream_foveated)
        foveated_area = cv2.UMat(foveated_area)
        a, b, r = 960, 512, 128
        img, mask = self.calculate_masked_circle(foveated_area, (a, b))
        return self.stack_images(peripheral_area, img, cv2.bitwise_not(mask))

    def extract_area(self, area: str, size: tuple) -> cv2.UMat:
        """
        Extract image from hex to numpy array
        :param area: image in hex
        :param size: size of the image
        :return: image as numpy array
        """
        area = np.frombuffer(area, dtype='uint8').reshape(size[1], size[0], 3)
        return area

    def stream_async(self, frame_peripheral: str, frame_foveated: str):
        """
        Helper method for async calculation
        :param frame_peripheral: peripheral image
        :param frame_foveated: foveated image
        :return: final image
        """
        frame = self.calc_frame(frame_peripheral, frame_foveated)
        if frame is not None:
            return frame

    def read_error(self, proc_peripheral: sp.Popen, proc_foveated: sp.Popen):
        """
        Read error stdout
        :param proc_peripheral: subprocess of error channel of peripheral stream
        :param proc_foveated:  subprocess of error channel of foveated stream
        :return: None
        """
        try:
            while proc_peripheral.stderr.readable() and proc_foveated.stderr.readable():
                print(f"{bcolors.WARNING}Peripheral: ", proc_peripheral.stderr.readline(), f"{bcolors.ENDC}")
                print(f"{bcolors.WARNING}Foveated: ", proc_foveated.stderr.readline(), f"{bcolors.ENDC}")
            print('finished errors')
        except SystemExit:
            pass

    def read_frames_async(self, proc_peripheral: sp.Popen, proc_foveated: sp.Popen):
        """
        Read the frames from the streams' console. Merge them accordingly and queue them up for main process
        :param proc_peripheral: stdout of the subprocess of the peripheral stream
        :param proc_foveated: stdout of the subprocess of foveated area
        :return: None
        """
        size_peripheral = self.size_stream_peripheral[0] * (self.size_stream_peripheral[1]) * 3
        size_foveated = self.size_stream_foveated[0] * self.size_stream_foveated[1] * 3

        executer = concurrent.futures.ThreadPoolExecutor()
        try:
            while not self.end_of_stream:
                frame_peripheral = proc_peripheral.stdout.read(size_peripheral)
                frame_foveated = proc_foveated.stdout.read(size_foveated)

                if frame_foveated == 0 or frame_peripheral == 0 or len(frame_foveated) == 0 or len(
                        frame_peripheral) == 0:
                    print('end of stream')
                    print('frame_foveated: ', frame_foveated)
                    print('frame_peripheral: ', frame_peripheral)
                    self.end_of_stream = True
                    break
                x = executer.submit(self.stream_async, frame_peripheral, frame_foveated)
                self.ImageQueue.put(x)
        except SystemExit:
            pass

    def stream(self):
        """
        Initialize both subprocessses for bot streams including error channels in threads.
        Read Queue of final images
        :return: None
        """
        self.initialize_cv2()

        sdp_file_peripheral = "VideoSettings/video_00_00_00_peripheral.sdp"
        sdp_file_foveated = "VideoSettings/video_00_00_00_foveated.sdp"
        proc_peripheral = self.initialize_ffmpeg(sdp_file_peripheral)
        proc_foveated = self.initialize_ffmpeg(sdp_file_foveated)
        read_frames = threading.Thread(target=self.read_frames_async, args=(proc_peripheral, proc_foveated))
        read_frames.start()
        self.threads.append(read_frames)

        while not self.end_of_stream:
            try:
                res: concurrent.futures.Future = self.ImageQueue.get(block=True, timeout=100)
                img: cv2.UMat = res.result(timeout=100)
                cv2.imshow('image', img)
                # self.video_writer.write(peripheral_area)
                self.last_frame_received = time.process_time()
            except queue.Empty:
                self.end_of_stream = True
                break

            if self.last_frame_received - time.process_time() > 1:
                self.end_of_stream = True
                break

            k = cv2.waitKey(20) & 0xFF
            if k == ord('q'):
                self.end_of_stream = True
                break

        for thread in self.threads:
            thread.join()

        cv2.destroyAllWindows()
        # self.video_writer.release()
        proc_peripheral.stdout.close()
        proc_peripheral.wait()
        proc_foveated.stdout.close()
        proc_foveated.wait()
        sys.exit()


if __name__ == '__main__':
    client = FoveatedStreamingClient(128, (1920, 1024), (256, 256), (512, 256))
    client.stream()
