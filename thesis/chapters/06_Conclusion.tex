\chapter{Conclusion}\label{chapter:conclusion}
In this thesis, a prototype of a streaming solution including foveated rendering and superresolution is developed and evaluated. This chapter describes the results and states the limitations of this work.
\section{Summary}
The proposed solution for optimizing the transmission for limited bandwidth and latency through foveated rendering and superresolution aimed to fulfil many requirements. These requirements are necessary to achieve a streaming solution, which help the user to control the robot appropriately and without having side effects. The first-of-its-kind solution transmits two streams, the foveated region and the peripheral region. Both regions are separated at the server by a received gaze. The separated regions are sent to the client through a specified protocol. The client receives the streams as well as the frame number connected to the gaze and can thus merge the frames correctly. A \gls{hmd} is connected to the client and shows the complete stream in \gls{vr}. The \gls{hmd} also predicts the current gaze and sends it through the client to the server. However, the time constraint of being faster than 125ms was not achieved. In the best case, a single frame is transmitted within 150 milliseconds, and in the worst case, a frame needs approximately 300 milliseconds. Moreover, the superresolution does not achieve its goal to replace the standard interpolation methods appropriately. The problem is the implementation of the superresolution, where the neural network works, but it cannot be implemented as the required additional operations are too time-consuming.
\par
Overall, this attempt to realize a real-time streaming solution with having a latency below 125 milliseconds uncovers many areas about what works and what does not. The presented streaming solution shows that the concept works and provides good results. In contrast, there are problems which have to be solved in future. One of the problems is the large latency, which is great for standard streaming solution but is not usable in the scenario of telepresence.

\section{Limitations}
There are some limitations of this project. One of them is the presented \gls{gan} being large and therefore occupies much \gls{vram}, which results in a small batch size. This also relates to the usability of using the \gls{gan} in a threaded environment. That means when too many images are loaded for superresolution at the same time, the software crashes. This problem also impacts Unity3D reserving also some \gls{vram}. In a single thread scenario, it cannot hold the FPS given as stated in \autoref{fig:UnityFPS}.
\par
As mentioned in the \autoref{chapter:implementation} the optical flow loss was dropped, because of hardware constraints. Facebook used for their training many \glspl{gpu} and still needed round about 48 hours to train the DeepFovea. This indicates that having this large dataset is still challenging for the best computers, even when the training is optimized and distributed.
\par
Finally, the whole project was developed and tested on one machine, leading to a bottleneck at the \gls{gpu}. As two streams are encoded and decoded on this machine as well as the rendering for the \gls{vr} and the \gls{ml} based superresolution a lack of performance is possible. 
\par
Possible solutions are discussed in \autoref{chapter:outlook}. Nevertheless, this project shows that this kind of real-time streaming for telepresence is possible, which is related to controlling a robot.